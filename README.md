# 2025年浙江省大学生科技创新活动计划（新苗人才计划）成果材料
2025-srtp 胡集源 胡思远 许瑞航

## 一、项目实施情况与研究内容

项目中期检查后，我们继续推进已有计划，分两个阶段实现羽毛球比赛视频的动作检测和解说生成。

### 1. 信息采集增强阶段：
输入一整场高水平羽毛球比赛的视频，先参考Automated Hit-frame Detection for Badminton Match Analysis论文，使用court R-CNN和keypoint R-CNN模型识别提取球员骨骼点和场地边缘，并提取球员在场地中的相对移动位置，使用SA-CNN(shot-angle)进行相机拍摄视角变化的检测，并分割出视频中各个回合的数据和击球瞬间，使用台科大的公开数据集ShuttleSet提供的帧级别标注和VideoBadminton 18分类击球动作数据集，训练比较了多种视频动作识别模型的效果，其中包括基于mmaction2 PoseC3D网络的骨骼点动作检测模型（须先将VideoBadminton数据集提取为NTU RGB 60骨骼点pkl格式）、基于SPOT的时空动作定位模型、基于VideoMAE、InternVideo2和PaddleVideo的端到端视频动作检测模型，其中SPOT和PoseC3D模型效果较好，均能够在A100上达到实时推理速度（20~30fps），
### 2. 解说生成和可视化分析阶段：
对第一阶段获取到的整场比赛的击球，移动数据进行详细的分析与可视化，使用LLaVA-Video-7B-Qwen2和videoChat-Flash-Qwen2_5-2B_res448两个长视频理解模型相结合，选择某一回合输入第一阶段获取到的动作序列，输出和动作序列对齐的解说词，采用基于Qwen3 api和ragflow的RAG模型进行对解说风格的深入理解（专业羽毛球解说语料库来源为b站up主小武行不行的20场经典比赛视频解说词（仅非盈利用途）），增强视频理解模型生成的解说，使用最新的CozyVoice-v1模型将自然生动的解说词转化为和视频回合对齐的语音解说，制作gradio前端便于展示

## 二、项目成果的学术价值

通过结合多种视频分析技术，如骨骼点检测、场地边缘识别、拍摄视角变化检测等，并将这些轻量级模型与长视频理解大模型相结合，初步完成了羽毛球动作识别和比赛解说生成这一靠端到端系统难以解决的任务。这种方法不仅提高了动作识别的准确性，同时也为类似体育赛事的自动化分析提供了新思路。同时，利用和改进现有的公开数据集，并通过实际应用验证了这些数据集的有效性。此外，项目中生成的新标注数据也为社区提供了宝贵资源。

## 三、项目成果的社会效益和经济效益

社会效益：

通过自动解说系统，可以更广泛地传播羽毛球比赛的知识和技术细节，帮助观众更好地理解比赛，激发大众参与羽毛球运动的兴趣。高质量的自动解说和可视化分析能够为观众带来更加丰富的观看体验。对羽毛球教练员和运动员来说，这种技术可以帮助他们分析比赛策略和技术执行情况，提高训练效果。

经济效益：

传统的人工解说需要耗费大量人力物力，而自动解说系统的开发成功可以在保证解说质量的同时大大减少成本开支。基于这一技术，可以开发出更多相关的增值服务，比如定制化的解说服务、比赛分析报告等，为企业开辟新的盈利模式。随着人们对体育娱乐需求的增长，该系统不仅可以应用于羽毛球，还可以拓展至其他体育项目，具有广阔的市场前景。

## 四、研究存在的不足和欠缺，尚需深入研究的问题

现存问题：

 	1. 超过2小时的比赛视频会出现显存溢出风险（峰值占用28GB）
 	2. 现有数据集未涵盖业余选手视频，要求视频录制质量较高，导致大众教学场景准确率下降 
 	3. 完整系统需RTX 3090以上显卡，制约移动端部署

后续研究方向：

    1. 开发记忆增强型视频理解模型，通过可扩展上下文窗口（目标32K tokens）解决长视频处理问题，
    2. 构建跨技能水平适应框架，利用领域泛化技术提升对业余球员的分析能力
    3. 目标在骁龙8 Gen3移动平台实现10fps实时推理，并在huggingface hub上部署space