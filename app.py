from tools.qwen_model import *
from tools.rag_with_qwen import *
import gradio as gr
import json
from openai import OpenAI  # å‡è®¾ OpenAI æ¨¡å—å¯ç”¨
import os
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Rectangle
import shutil
from pathlib import Path
import subprocess
from moviepy import *
from collections import Counter
import dashscope
from dashscope.audio.tts_v2 import *

# é…ç½® API å¯†é’¥
api_key = "your-api-key"
os.environ["OPENAI_BASE_URL"] = 'https://api.gpt.ge/v1'
client = OpenAI(api_key=api_key)

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Circle

# åœºåœ°å‚æ•°ï¼ˆåŸºäºå›¾åƒåæ ‡ç³»ï¼‰
COURT_CENTER = (150, 445)   # åœºåœ°ä¸­å¿ƒç‚¹ (x,y)
COURT_CENTER_BIAS = (150, 400)  # åœºåœ°ä¸­å¿ƒåç§»é‡ï¼ˆx,yï¼‰
COURT_WIDTH = 255           # åœºåœ°æœ‰æ•ˆå®½åº¦ï¼ˆxè½´èŒƒå›´22.5~277.5ï¼‰
COURT_HEIGHT = 590          # åœºåœ°æœ‰æ•ˆé«˜åº¦ï¼ˆyè½´èŒƒå›´150~740ï¼‰
LEFT_DOWN = (22.5, 150)      # åœºåœ°å·¦ä¸‹è§’åæ ‡


# æ–°å¢çŠ¶æ€ç®¡ç†
chat_history_state = gr.State([])  # ç”¨äºå­˜å‚¨å®Œæ•´å¯¹è¯å†å²


# ç±»åˆ«é¢œè‰²æ˜ å°„
COLOR_MAP = {
    0: "#FF6B6B",  # çº¢è‰²
    1: "#4ECDC4",  # é’è‰²
    2: "#45B7D1",  # è“è‰²
    3: "#96CEB4",  # ç»¿è‰²
    4: "#FFEEAD",  # é»„è‰²
    5: "#D4A5A5"   # ç²‰è‰²
}

# ç±»åˆ«åç§°æ˜ å°„
LABEL_MAP = {
    0: "net shot",
    1: "lift",
    2: "smash",
    3: "defensive drive",
    4: "clear",
    5: "flat shot"
}
def count_reasons(df):
    win_reasons = df['win_reason'].dropna()
    lose_reasons = df['lose_reason'].dropna()

    win_reason_counts = Counter(win_reasons)
    lose_reason_counts = Counter(lose_reasons)

    return win_reason_counts, lose_reason_counts

# ä¿®æ”¹ plot_reason_counts å‡½æ•°ä»¥æ¥æ”¶ ax å‚æ•°
def plot_reason_counts(win_reason_counts, lose_reason_counts, ax=None):
    # åˆ›å»ºç”»å¸ƒ
    fig = plt.figure(figsize=(12, 6))
    # åˆ›å»ºä¸¤ä¸ªå­å›¾
    ax1 = plt.subplot(121) # å·¦è¾¹çš„å­å›¾
    ax2 = plt.subplot(122) # å³è¾¹çš„å­å›¾

    # Plotting win_reason counts
    win_reasons, win_counts = zip(*win_reason_counts.items())
    ax1.bar(win_reasons, win_counts, color='lightgreen')
    ax1.set_xlabel('Win Reason')
    ax1.set_ylabel('Count')
    ax1.set_title('Win Reason Counts')
    ax1.tick_params(axis='x', rotation=45)

    # Plotting lose_reason counts
    lose_reasons, lose_counts = zip(*lose_reason_counts.items())
    ax2.bar(lose_reasons, lose_counts, color='lightcoral')
    ax2.set_xlabel('Lose Reason')
    ax2.set_ylabel('Count')
    ax2.set_title('Lose Reason Counts')
    ax2.tick_params(axis='x', rotation=45)

    # å¦‚æœ ax è¢«æä¾›ï¼Œåˆ™å°† ax1 å’Œ ax2 çš„å†…å®¹ç»˜åˆ¶åˆ°æŒ‡å®šçš„ ax ä¸­
    if ax is not None:
        print("Using provided axes for plotting.")
        for a in [ax1, ax2]:
            for bar in a.containers[0]:
                a.draw_artist(bar)
            a.relim()
            a.autoscale_view()
        fig.canvas.draw_idle()


def visualize_match_data(match_segment):    
    # åˆ’åˆ†æ¯”èµ›æ®µè½
    if match_segment == "ç¬¬ä¸€åœº":
        df = pd.read_csv("/home/jovyan/2024-srtp/srtp-final/Anthony_Sinisuka_Ginting_Lee_Zii_Jia_HSBC_BWF_WORLD_TOUR_FINALS_2020_QuarterFinals/set1.csv")
    elif match_segment == "ç¬¬äºŒåœº":
        df = pd.read_csv("/home/jovyan/2024-srtp/srtp-final/Anthony_Sinisuka_Ginting_Lee_Zii_Jia_HSBC_BWF_WORLD_TOUR_FINALS_2020_QuarterFinals/set2.csv")
    else:
        df = pd.read_csv("/home/jovyan/2024-srtp/srtp-final/Anthony_Sinisuka_Ginting_Lee_Zii_Jia_HSBC_BWF_WORLD_TOUR_FINALS_2020_QuarterFinals/set3.csv")
    sub_df = df.copy()

    type_mapping = {
        'æ”¾å°çƒ': 'net shot',
        'æ“‹å°çƒ': 'return net',
        'æ®ºçƒ': 'smash',
        'é»æ‰£': 'wrist smash',
        'æŒ‘çƒ': 'lob',
        'é˜²å®ˆå›æŒ‘': 'defensive return lob',
        'é•·çƒ': 'clear',
        'å¹³çƒ': 'drive',
        'å°å¹³çƒ': 'driven flight',
        'å¾Œå ´æŠ½å¹³çƒ': 'back-court drive',
        'åˆ‡çƒ': 'drop',
        'éæ¸¡åˆ‡çƒ': 'passive drop',
        'æ¨çƒ': 'push',
        'æ’²çƒ': 'rush',
        'é˜²å®ˆå›æŠ½': 'defensive return drive',
        'å‹¾çƒ': 'cross-court net shot',
        'ç™¼çŸ­çƒ': 'short service',
        'ç™¼é•·çƒ': 'long service'
    }

    # è®¾ç½®å­—ä½“æ”¯æŒä¸­æ–‡æ˜¾ç¤º
    plt.rcParams['font.sans-serif'] = ['SimHei', 'FangSong']  # æŒ‡å®šé»˜è®¤å­—ä½“
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå· '-' æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

    # åˆ›å»ºç”»å¸ƒï¼š3è¡Œ1åˆ—ï¼Œé«˜åº¦å¢åŠ ä¸€ç‚¹
    fig, (ax1, ax2, ax3,ax4) = plt.subplots(4, 1, figsize=(10, 20),gridspec_kw={'height_ratios': [1, 1, 1.5, 1]})
    plt.subplots_adjust(hspace=0.6)  # å¢åŠ å­å›¾é—´è·

    # å›¾1ï¼šå‡»çƒç±»å‹åˆ†å¸ƒï¼ˆè‹±æ–‡ï¼‰
    sub_df['type_en'] = sub_df['type'].map(type_mapping)
    type_counts = sub_df['type_en'].value_counts()
    ax1.bar(type_counts.index, type_counts.values, color='skyblue')
    ax1.set_title('Shot Type Distribution')
    ax1.tick_params(axis='x', rotation=90)

    # å›¾2ï¼šå‡»çƒ-è½ç‚¹çƒ­åŠ›å›¾
    hit_areas = pd.crosstab(sub_df['hit_area'], sub_df['landing_area'])
    im = ax2.imshow(hit_areas, cmap='YlGnBu')
    ax2.set_title('Hit-Landing Area Matrix')
    ax2.set_xlabel('Landing Area')
    ax2.set_ylabel('Hit Area')
    plt.colorbar(im, ax=ax2)
    win_reason_mapping = {
    "å°æ‰‹å‡ºç•Œ": "Opponent Out of Bounds",
    "å°æ‰‹æ›ç¶²": "Opponent Netted",
    "å°æ‰‹æœªéç¶²": "Opponent Failed to Clear the Net",
    "è½åœ°è‡´å‹": "Winning Shot (Ball Landed)",
    "å°æ‰‹è½é»åˆ¤æ–·å¤±èª¤": "Opponent Misjudged Landing Spot"
    }
    # å›¾3ï¼šWin Reason Countsï¼ˆå¾—åˆ†åŸå› ç»Ÿè®¡ï¼‰
    win_reasons_en = sub_df['win_reason'].dropna().map(win_reason_mapping)
    win_reason_counts = Counter(win_reasons_en)

    win_reasons_list, win_counts_list = zip(*win_reason_counts.items())
    ax3.bar(win_reasons_list, win_counts_list, color='lightgreen')
    ax3.set_title('Win Reason Counts')
    ax3.set_xlabel('Win Reason')
    ax3.set_ylabel('Count')
    ax3.tick_params(axis='x', rotation=45)
    lose_reason_mapping = {
    "å°æ‰‹è½åœ°è‡´å‹": "Opponent's Winning Shot (Ball Landed)",
    "æ›ç¶²": "Netted",
    "æœªéç¶²": "Failed to Clear the Net",
    "å‡ºç•Œ": "Out of Bounds",
    "è½é»åˆ¤æ–·å¤±èª¤": "Misjudged Landing Spot"
    }
    # å›¾4ï¼šLose Reason Countsï¼ˆå¤±åˆ†åŸå› ç»Ÿè®¡ï¼‰
    lose_reasons = sub_df['lose_reason'].dropna().map(lose_reason_mapping)
    lose_reason_counts = Counter(lose_reasons)
    lose_reasons_list, lose_counts_list = zip(*lose_reason_counts.items())
    ax4.bar(lose_reasons_list, lose_counts_list, color='lightcoral')
    ax4.set_title('Lose Reason Counts')
    ax4.set_xlabel('Lose Reason')
    ax4.set_ylabel('Count')
    ax4.tick_params(axis='x', rotation=45)
    # è‡ªåŠ¨è°ƒæ•´å¸ƒå±€
    plt.tight_layout()

    return fig


def create_timeline_plot(action_list, video_duration):
    """ç”Ÿæˆæ—¶é—´è½´å›¾"""
    # è®¡ç®—è§†é¢‘æ—¶é•¿
    action_list = [1,2,3,4,3,2,5,0,1,3,2,4,5,0,1,2,3,4,5]
    fig, ax = plt.subplots(figsize=(30, 1))
    ax.set_xlim(0, video_duration)
    ax.set_ylim(0, 1)
    ax.axis('off')

    # åˆå¹¶è¿ç»­ç›¸åŒåŠ¨ä½œ
    current_action = action_list[0]
    start_time = 0
    for i in range(1, len(action_list)):
        if action_list[i] != current_action or i == len(action_list)-1:
            end_time = i
            ax.add_patch(Rectangle(
                (start_time, 0), 
                end_time - start_time, 1,
                facecolor=COLOR_MAP[current_action],
                edgecolor='white'
            ))
            start_time = end_time
            current_action = action_list[i]

    # æ·»åŠ å›¾ä¾‹
    legend_handles = []
    for label_id, color in COLOR_MAP.items():
        legend_handles.append(
            Rectangle((0,0),1,1, facecolor=color, label=LABEL_MAP[label_id])
        )
    ax.legend(handles=legend_handles, 
             loc='upper center',
             bbox_to_anchor=(0.5, -0.2),
             ncol=6)

    return fig


# è®¾ç½® DashScope API Key å’Œæ¨¡å‹å‚æ•°
dashscope.api_key = "sk-cd5c2f5fcddd49c5b4e4169d5021d8e2"
TTS_MODEL = "cosyvoice-v1"

def commentary_generator(rally_id, chat_response, rally_data,voice_choice):
    # è·¯å¾„é…ç½®
    rally_id = 3
    rally_data = rally_data["rally"]
    rally= rally_data[rally_id-1]
    start_frame = int(rally[0])
    end_frame = int(rally[1])
    base_dir = "/home/jovyan/2024-srtp/srtp-final"
    json_path = os.path.join(base_dir, "hit_frame_detection", "outputs", "joints", "input_video", f"rally_{rally_id}.json")
    video_input_path = os.path.join(base_dir, "hit_frame_detection", "outputs", "videos", "input_video", "video_1_h264.mp4")
    video_output_path = os.path.join(base_dir, "output_videos", f"video_{rally_id}_with_commentary.mp4")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(video_output_path), exist_ok=True)

    # åŠ è½½ JSON æ•°æ®
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    hit_frames = data.get("hit frames", [])
    print(f"åŠ è½½åˆ° {len(hit_frames)} ä¸ªå‡»çƒæ—¶é—´ç‚¹")

    # è§£æ chat_responseï¼ˆæ ¼å¼ï¼š[{"hit_num": 2, "comment": "..."}, ...]ï¼‰
    try:
        commentaries = json.loads(chat_response)
    except json.JSONDecodeError:
        raise ValueError("è§£è¯´è¯æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¾“å…¥çš„ JSON æ•°æ®ï¼")

    # æ£€æŸ¥æ ¼å¼æ˜¯å¦æ­£ç¡®
    if not isinstance(commentaries, list) or not all(
        isinstance(item, dict) and "hit_num" in item and "comment" in item for item in commentaries
    ):
        raise ValueError("è§£è¯´è¯æ ¼å¼é”™è¯¯ï¼Œè¯·ç¡®ä¿æ¯ä¸ªè§£è¯´è¯åŒ…å« 'hit_num' å’Œ 'comment' å­—æ®µï¼")

    # åŠ è½½åŸå§‹è§†é¢‘
    video = VideoFileClip(video_input_path)

    # åˆå§‹åŒ–ä¸´æ—¶æ–‡ä»¶å¤¹ç”¨äºå­˜å‚¨éŸ³é¢‘
    with tempfile.TemporaryDirectory() as tmpdir:
        audio_clips = []

        # åˆå§‹åŒ–åˆæˆå™¨
        synthesizer = SpeechSynthesizer(model=TTS_MODEL, voice=voice_choice)

        # éå†æ¯ä¸€æ¡è§£è¯´è¯
        for i, item in enumerate(commentaries):
            hit_num = item["hit_num"]
            comment = item["comment"]

            # æ ¹æ® hit_num è·å–å¯¹åº”çš„å¸§ç¼–å·
            if hit_num < 1 or hit_num > len(hit_frames):
                raise ValueError(f"æ— æ•ˆçš„ hit_num: {hit_num}ï¼Œè¯·æ£€æŸ¥è§£è¯´è¯ä¸­çš„ hit_num æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼")

            frame_time = hit_frames[hit_num - 1]  # hit_num æ˜¯ä» 1 å¼€å§‹è®¡æ•°çš„

            # å¸§è½¬ç§’ï¼ˆå‡è®¾å¸§ç‡æ˜¯ 30 fpsï¼‰
            second = frame_time / 30.0
            print(f"ç¬¬{i+1}å¥è§£è¯´ï¼šåœ¨ {second:.2f}s å¤„æ’å…¥ï¼Œhit_num: {hit_num}")

            # ç”Ÿæˆ TTS éŸ³é¢‘
            output_audio_path = os.path.join(tmpdir, f"tts_{i}.mp3")
            audio_data = synthesizer.call(comment)
            with open(output_audio_path, 'wb') as f:
                f.write(audio_data)

            # åŠ è½½éŸ³é¢‘ç‰‡æ®µå¹¶è®¾ç½®å¼€å§‹æ—¶é—´
            audio_clip = AudioFileClip(output_audio_path).set_start(second)
            audio_clips.append(audio_clip)

            # é˜²æ­¢å¹¶å‘è¯·æ±‚é™åˆ¶
            time.sleep(1)

        # åˆæˆåŸè§†é¢‘éŸ³é¢‘ + è§£è¯´éŸ³é¢‘
        final_audio = CompositeAudioClip([video.audio] + audio_clips) if video.audio else CompositeAudioClip(audio_clips)

        # è®¾ç½®è§†é¢‘éŸ³é¢‘å¹¶å¯¼å‡º
        video_with_audio = video.set_audio(final_audio)
        video_with_audio.write_videofile(video_output_path, codec="libx264", audio_codec="aac")

        print(f"è§†é¢‘å·²ä¿å­˜è‡³: {video_output_path}")


def get_action_plot(rally_choice,rally_data):
    
    video_path_part = rally_choice.split("/")[-1].split(".mp4")[0]
    # æå–rally_idï¼š
    rally_id = int(video_path_part.split("_")[-1])
    # ç”Ÿæˆæ—¶é—´è½´å›¾
    video_path_part = rally_choice.split("/")[-1].split(".mp4")[0]
    # æå–rally_idï¼š
    rally_id = int(video_path_part.split("_")[-1])
    pred_list = get_actions(rally_id)
    # æå–rally_dataä¸­çš„rally_idå¯¹åº”çš„å¸§èŒƒå›´
    rally_data = rally_data["rally"]
    rally= rally_data[rally_id-1]
    start_frame = int(rally[0])
    end_frame = int(rally[1])
    duration = (end_frame - start_frame) / 30  # å‡è®¾å¸§ç‡ä¸º30fps
    fig = create_timeline_plot(pred_list, duration)
    return fig


def get_actions(rally_id):
      #ä»../joints/ä¸­è¯»å–csvæ–‡ä»¶
    action_cmd = f"bash /home/jovyan/2024-srtp/srtp-final/mmaction2/get_action.sh {rally_id}"
    subprocess.run(action_cmd, shell=True, check=True)
    json_path = "/home/jovyan/2024-srtp/srtp-final/mmaction2/output_with_names.json"
    with open(json_path, "r") as f:
        data = json.load(f)
    pred_list = []
    label_names=[
    "net shot",
    "lift",
    "smash",
    "defensive drive",
    "clear",
    "flat shot"
    ]
    for entry in data:
        pred_label = entry['pred_label'][0]
        pred_label_name = label_names[pred_label]
        pred_list.append(pred_label)
    print(pred_list)
    return pred_list
# ä¿®æ”¹åçš„é¢„æµ‹å‡½æ•°
def qwen_predict(user_input, sport, player1_name, player2_name,rally_data,rally_choice):
    # åŸæœ‰é¢„æµ‹é€»è¾‘ï¼ˆå‡è®¾è¿”å›å­—ç¬¦ä¸²ï¼‰
    # è§£æè·¯å¾„ï¼švideo_{rally_id}_h264.mp4,æå–rally_id
    video_path_part = rally_choice.split("/")[-1].split(".mp4")[0]
    # æå–rally_idï¼š
    rally_id = int(video_path_part.split("_")[-1])
    # æå–rally_dataä¸­çš„rally_idå¯¹åº”çš„å¸§èŒƒå›´
    rally_data = rally_data["rally"]
    rally= rally_data[rally_id-1]
    start_frame = int(rally[0])
    end_frame = int(rally[1])
    # è·å–åŠ¨ä½œåºåˆ—
    action_list = get_actions(rally_id)
    player_nickname_map = {
    "æ—ä¸¹": "ä¸¹",
    "æå®—ä¼Ÿ": "æ",
    "è°Œé¾™": "é¾™",
    "æ¡ƒç”°è´¤æ–—": "æ¡ƒ",
    "å®‰èµ›é¾™": "é¾™",
    "çŸ³å®‡å¥‡": "çŸ³å¤´",
    "ä¹”çº³å¦Â·å…‹é‡Œæ–¯è’‚": "ä¹”",
    "ææ¢“å˜‰": "æ",
    "å®‰ä¸œå°¼Â·è¥¿å°¼è‹å¡Â·é‡‘å»·": "é‡‘å»·",
    "å‘¨å¤©æˆ": "å‘¨"
    }
    player1_nickname = player_nickname_map.get(player1_name, player1_name)
    player2_nickname = player_nickname_map.get(player2_name, player2_name)  
    prompt = f"""
        Generate a professional badminton commentary in Chinese for a {sport} match between {player1_name} (Player 1) and {player2_name} (Player 2). 

        Key requirements:
        1. Output Format:
        Return only a valid JSON array of objects with format, where hit_num is the index of the hit in the rally (1-based), and comment is the generated commentary for that hit:
        [
        {
            "hit_num": 2,
            "comment": "..."
        }
        {
            "hit_num": 3,
            "comment": "..."
        },
        ...
        ]
        

        2. Identify and classify each shot type from these 20 categories:
        [net shot, smash, wrist smash, lob, defensive return lob, clear, drive, 
        driven flight, back-court drive, drop, passive drop, push, rush, 
        defensive return drive, cross-court net shot, short service, 
        long service, defensive shot, push/rush]

        3. Each comment sentence should include:
        - Name of the player who hit the ball in short: the last name of the player, e.g. "æ" for "æå®—ä¼Ÿ"
        - Player action sequence (with shot types)
        - Tactical analysis
        - Score update(get the match score from left-upper corner of the video)
        - Exciting/exclamatory commentary phrase

        4. Style guidelines:
        - Use nicknames or abbreviations like â€œ{player1_nickname}â€ and â€œ{player2_nickname}â€ when appropriate.
        - Chinese commentary only
        - Short, dynamic sentences (3 to 7 words for action descriptions)
        - Tactical insights e.g. ("æ§ç½‘æŠ¢æ”»", "é€¼å‹åº•çº¿")
        - Do not generate too much emotional highlights

        Generate commentary that:
        1. Precisely identifies each shot type
        2. Explains player strategies
        3. Maintains exciting play-by-play flow
        4. Updates score regularly
        5. Avoids excessive emotional highlights
        6. Only Chinese commentary
        extra requirements by user:
        {user_input}
        """
    print(prompt)
    prediction = get_qwen_ans(rally_choice, prompt, model, tokenizer, max_num_frames, generation_config) 
    return prediction

# å¯¹è¯å†å²æ›´æ–°å‡½æ•°
def update_chat_history(video_input, user_input, history):
    # è·å–æ¨¡å‹å“åº”
    model_response = qwen_predict(video_input, user_input)
    
    # æ„å»ºæ–°çš„å¯¹è¯æ¡ç›®ï¼ˆåŒ¹é…å›¾åƒä¸­çš„æ¶ˆæ¯æ ¼å¼ï¼‰
    new_entry = [
        {"role": "user", "content": f"ğŸ“¥ è¾“å…¥ï¼š{user_input}"},
        {"role": "assistant", "content": f"âš¡ å“åº”ï¼š{model_response}"}
    ]
    
    # æ›´æ–°å†å²è®°å½•
    updated_history = history + new_entry if history else new_entry
    
    # ä¿ç•™æœ€æ–°5æ¡å¯¹è¯ï¼ˆé˜²æ­¢æº¢å‡ºï¼‰
    return updated_history[-10:]

def coordinate_transform(df):
    """åæ ‡å˜æ¢æµç¨‹ï¼šä¸­å¿ƒå¯¹é½â†’ç¼©æ”¾"""
    # åŸå§‹æ•°æ®çŸ©é˜µï¼ˆç¤ºä¾‹å­—æ®µï¼‰
    df = df.dropna(subset=['hit_x', 'hit_y', 
                            'landing_x', 'landing_y',
                            'player_location_x', 'player_location_y',
                            'opponent_location_x', 'opponent_location_y'])
    hit_points = df[['hit_x', 'hit_y']].values
    landing_points = df[['landing_x', 'landing_y']].values
    player_locations = df[['player_location_x', 'player_location_y']].values
    opponent_locations = df[['opponent_location_x', 'opponent_location_y']].values
    print(hit_points.shape, landing_points.shape, player_locations.shape, opponent_locations.shape)
    # è®¡ç®—x,yåæ ‡çš„å‡å€¼ï¼ˆæ•°æ®ä¸­å¿ƒï¼‰
    all_points = np.vstack((hit_points, landing_points, player_locations, opponent_locations))
    print(all_points.shape)
    data_center = np.mean(all_points, axis=0)
    
    
    # Step3: å¹³ç§»å¯¹é½åœºåœ°ä¸­å¿ƒ
    offset = np.array(COURT_CENTER) - data_center
    print(offset)
    aligned = all_points + offset
    
    # Step4: è‡ªé€‚åº”ç¼©æ”¾
    # è®¡ç®—æ•°æ®èŒƒå›´
    x_min, x_max = np.min(aligned[:,0]), np.max(aligned[:,0])
    y_min, y_max = np.min(aligned[:,1]), np.max(aligned[:,1])
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿ç•™5%è¾¹ç•Œï¼‰
    scale_x = COURT_WIDTH * 1.1 / (x_max - x_min)
    scale_y = COURT_HEIGHT * 1.1 / (y_max - y_min)
    
    rotation_matrix = np.array([[scale_x, 0],
                                [0, scale_y]])
    print("scale_x, scale_y", scale_x, scale_y)

    hit_points_transformed = np.dot(hit_points, rotation_matrix) 
    landing_points_transformed = np.dot(landing_points, rotation_matrix)
    player_locations_transformed = np.dot(player_locations, rotation_matrix) 
    opponent_locations_transformed = np.dot(opponent_locations, rotation_matrix) 
    all_points_transformed = np.vstack((hit_points_transformed, landing_points_transformed, player_locations_transformed, opponent_locations_transformed))
    data_center_transformed = np.mean(all_points_transformed, axis=0)
    print("data_center_transformed", data_center_transformed)
    # è®¡ç®—æ–°çš„åç§»é‡
    offset_transformed = np.array(COURT_CENTER_BIAS) - data_center_transformed
    print("offset_transformed", offset_transformed)
    # å¹³ç§»å¯¹é½
    hit_points_transformed += offset_transformed
    landing_points_transformed += offset_transformed
    player_locations_transformed += offset_transformed
    opponent_locations_transformed += offset_transformed

    # æ›´æ–° DataFrame
    df[['hit_x', 'hit_y']] = hit_points_transformed
    df[['landing_x', 'landing_y']] = landing_points_transformed
    df[['player_location_x', 'player_location_y']] = player_locations_transformed
    df[['opponent_location_x', 'opponent_location_y']] = opponent_locations_transformed

    return df



def draw_heatmap(ax, df, player):
    """ç»˜åˆ¶åˆ†å±‚çƒ­åŠ›é¥¼å›¾"""
    player_df = df[(df['player'] == player) & 
                  (df['landing_area'] <= 10)]
    
    # ç»Ÿè®¡åŒºåŸŸå‡»çƒé¢‘æ¬¡
    area_counts = player_df['landing_area'].value_counts()
    max_count = area_counts.max() if not area_counts.empty else 1
    
    # è®¾ç½®æ¸å˜è‰²
    colors = plt.cm.Reds(np.linspace(0.3, 1, len(area_counts)))
    
    for (area, count), color in zip(area_counts.items(), colors):
        if area not in AREA_CENTERS:
            continue
            
        # è°ƒæ•´å‚ç›´ä½ç½®
        x, y = AREA_CENTERS[area]
        if player == 'B':
            y = COURT_HEIGHT - y  # ä¸‹åŠéƒ¨åˆ†é•œåƒ
        
        # åŠ¨æ€è®¡ç®—åŠå¾„å’Œé€æ˜åº¦
        radius = 40 + (count / max_count) * 80
        alpha = 0.4 + (count / max_count) * 0.4
        
        ax.add_patch(Circle(
            (x, y), radius=radius,
            facecolor=color, edgecolor='white',
            linewidth=0.8, alpha=alpha
        ))
        
        # æ·»åŠ é¢‘æ¬¡æ ‡æ³¨
        ax.text(x, y, str(count), 
               ha='center', va='center',
               color='white', fontsize=10, 
               fontweight='bold')


def draw_match_data(mode='all'):
    # å¤ç”¨ä¹‹å‰çš„åœºåœ°ç»˜åˆ¶å‡½æ•°
    fig = draw_badminton_court()  
    ax = fig.gca()
    
    # è¯»å–æ¯”èµ›æ•°æ®
    df = pd.read_csv("/home/jovyan/2024-srtp/srtp-final/Anthony_Sinisuka_Ginting_Lee_Zii_Jia_HSBC_BWF_WORLD_TOUR_FINALS_2020_QuarterFinals/set1.csv")
    df = coordinate_transform(df)  # æ‰§è¡Œåæ ‡å˜æ¢
    
    # å¯è§†åŒ–å‚æ•°è®¾ç½®
    plot_config = {
        'hit_point': {'color': 'red', 'marker': 'o', 's': 80},
        'landing_point': {'color': 'blue', 'marker': 'X', 's': 100},
        'player_A': {'color': 'lime', 'marker': 'P', 's': 120},
        'player_B': {'color': 'yellow', 'marker': 'D', 's': 120},
        'trajectory': {'color': 'white', 'linestyle': '-', 'linewidth': 0.3}
    }

    for _, row in df.iterrows():
        if(mode == 'ball' or mode == 'all'):
            # å‡»çƒè½¨è¿¹å¯è§†åŒ–
            ax.plot([row['hit_x'], row['landing_x']],
                    [row['hit_y'], row['landing_y']],
                    **plot_config['trajectory'])
            # å‡»çƒç‚¹æ ‡è®°
            ax.scatter(row['hit_x'], row['hit_y'],
                    label='hit', **plot_config['hit_point'])
            ax.scatter(row['landing_x'], row['landing_y'],
                    label='land', **plot_config['landing_point'])
            ax.add_patch(Circle((row['landing_x'], row['landing_y']), 
                            radius=1, fc='none', ec='cyan', lw=0.3))

        
        if(mode == 'player' or mode == 'all'):
            player_color = plot_config['player_A'] if row['player'] == 'A' else plot_config['player_B']
            ax.scatter(row['player_location_x'], row['player_location_y'],
                    label=f'player {row["player"]}', **player_color)
            ax.scatter(row['opponent_location_x'], row['opponent_location_y'],
                    label=f'player {row["player"]}', **player_color)
       

    # æ·»åŠ æ™ºèƒ½å›¾ä¾‹ï¼ˆè‡ªåŠ¨å»é‡ï¼‰
    handles, labels = ax.get_legend_handles_labels()
    unique_labels = dict(zip(labels, handles))  # å»é‡
    ax.legend(unique_labels.values(), unique_labels.keys(),
              loc='upper left', fontsize=8, ncol=2)

    return fig


def draw_badminton_court():
    fig, ax = plt.subplots(figsize=(6, 12), dpi=80)
    fig.set_facecolor((0/255, 127/255, 102/255))  # è®¾ç½®èƒŒæ™¯é¢œè‰²
    ax.set_facecolor((0/255, 127/255, 102/255))
    
    # è®¾ç½®åæ ‡èŒƒå›´ï¼ˆå•ä½ï¼šå˜ç±³ï¼‰
    ax.set_aspect('equal')
    ax.axis('off')

    # ç»˜åˆ¶å¤–è¾¹æ¡†
    outer = Rectangle((22.5, 150), 255, 590, linewidth=4, 
                     edgecolor='white', facecolor='none')
    ax.add_patch(outer)

    # ç»˜åˆ¶å†…è¾¹æ¡†
    # inner = Rectangle((45, 195), 210, 500, linewidth=2,
    #                  edgecolor='white', facecolor='none')
    # ax.add_patch(inner)

    #æŠŠå†…è¾¹æ¡†æ”¹æˆå››æ¡çº¿ï¼Œå³åŸæ¥å†…è¾¹æ¡†çš„å»¶ç”³
    #å„ä¸ªå‚æ•°çš„æ„ä¹‰ï¼›
    # [x1, x2]ï¼šçº¿æ®µçš„èµ·å§‹å’Œç»“æŸä½ç½®
    # [y1, y2]ï¼šçº¿æ®µçš„èµ·å§‹å’Œç»“æŸä½ç½®
    ax.plot([22.5, 275.5], [195, 195], color='white', linewidth=2)  # ä¸Šè¾¹çº¿
    ax.plot([22.5, 275.5], [695, 695], color='white', linewidth=2)  # ä¸‹è¾¹çº¿
    ax.plot([45, 45], [150, 695+45], color='white', linewidth=2)  # å·¦è¾¹çº¿
    ax.plot([255, 255], [150, 695+45], color='white', linewidth=2)  # å³è¾¹çº¿
    

    # ç»˜åˆ¶ä¸­çº¿
    ax.plot([22.5, 277.5], [445, 445], color='white', linewidth=2)
    ax.plot([150, 150], [150, 150+295/3*2], color='white', linewidth=2)
    ax.plot([150, 150], [740-295/3*2, 740], color='white', linewidth=2)

    # ç»˜åˆ¶å‘çƒçº¿
    for y in [150+295/3*2, 740-295/3*2]:
        ax.plot([22.5, 277.5], [y, y], color='white', linewidth=2)

    # ç»˜åˆ¶ç½‘æ ¼çº¿ï¼ˆæ¨ªå‘ï¼‰
    for y in [150 + 295/3 * i for i in range(1,2)]:
        ax.plot([22.5, 277.5], [y, y], color='#25cf98', linewidth=1)

    for y in [740-295/3 * i for i in range(1,2)]:
        ax.plot([22.5, 277.5], [y, y], color='#25cf98', linewidth=1)

    # ç»˜åˆ¶ç½‘æ ¼çº¿ï¼ˆçºµå‘ï¼‰
    for x in [22.5 + 255/3 * i for i in [1,2]]:
        ax.plot([x, x], [150, 740], color='#25cf98', linewidth=1)

    # æ·»åŠ æ–‡å­—æ ‡ç­¾
    positions = [
        (72.5, 150+295/6*5, "1"), (157.5, 150+295/6*5, "2"), (242.5, 150+295/6*5, "3"),
        (72.5, 150+295/2, "4"), (157.5, 150+295/2, "5"), (242.5, 150+295/2, "6"),
        (72.5, 150+295/6+10, "7"), (157.5, 150+295/6+10, "8"), (242.5, 150+295/6+10, "9"),
        (72.5, 740-295/6*5, "3"), (157.5, 740-295/6*5, "2"), (242.5, 740-295/6*5, "1"),
        (72.5, 740-295/2, "6"), (157.5, 740-295/2, "5"), (242.5, 740-295/2, "4"),
        (72.5, 740-295/6-10, "9"), (157.5, 740-295/6-10, "8"), (242.5, 740-295/6-10, "7")
    ]
    
    for x, y, text in positions:
        ax.text(x, y, text, color='#25cf98', ha='center', va='center', fontsize=20)

    return fig


def ragflow_predict(chat_response, sport, player1_name, player2_name):
    # ä¾› Gradio è°ƒç”¨çš„æ¥å£å‡½æ•°
# def query_rag(question: str) -> str:
#     return rag_service.query(question)
    prompt = f"""
    Generate a professional badminton commentary in Chinese for a {sport} match between {player1_name} (Player 1) and {player2_name} (Player 2).
    Here is the initially generated commentary:
    {chat_response}
    Key requirements:
    1. Output Format:
    Return only a valid JSON array of objects with format, where hit_num is the index of the hit in the rally (1-based), and comment is the generated commentary for that hit:
    [
    {
        "hit_num": 2,
        "comment": "..."
    }
    {
        "hit_num": 3,
        "comment": "..."
    },
    ...
    ]
    2. Inhance the commentary by:
    - base on the initial commentary
    - base on the database knowledge of badminton commentary
    - Adding more tactical analysis
    - Including more player actions
    - Making it more exciting
    3. Style guidelines:
    - Use nicknames or abbreviations like â€œ{player1_name}â€ and â€œ{player2_name}â€ when appropriate.
    - Chinese commentary only
    - Short, dynamic sentences (3 to 7 words for action descriptions)
    - Tactical insights e.g. ("æ§ç½‘æŠ¢æ”»", "é€¼å‹åº•çº¿")
    """
    ans = query_rag(prompt)
    return ans


def predict(message, history):
    history_openai_format = []
    for human, assistant in history:
        history_openai_format.append({"role": "user", "content": human})
        history_openai_format.append({"role": "assistant", "content": assistant})
    history_openai_format.append({"role": "user", "content": message})

    response = client.chat.completions.create(
        model='gpt-3.5-turbo',
        messages=history_openai_format,
        temperature=1.0,
        stream=True
    )

    partial_message = ""
    for chunk in response:
        if chunk.choices[0].delta.content is not None:
            partial_message += chunk.choices[0].delta.content
            yield partial_message

def process_video(video_file, sport, structured_text):
    video_file.save_to_disk("temp_video.mp4")  # Save the uploaded video to disk
    output = {
        "video_processed": True,
        "sport": sport,
        "structured_text": structured_text,
        "message": "Video processing completed!"
    }
    return json.dumps(output, indent=4)

def get_today():
    import datetime
    file_path_vid =  datetime.datetime.now().strftime("%Y-%m-%d")
    save_dir = f"data/{file_path_vid}"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    return file_path_vid
    
def segment_video(video_input):
    if video_input is None:
        return "No video input provided.", None
    
    # mv outputs outputs_old
    # rm -rf ./videos
    # mkdir videos
    # cp ../data/tennis/test_videos/$VIDEO.mp4 ./videos
    # echo "output cleaned"
    # mkdir outputs
    # cd src
    # python main.py

    # 1. åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
    base_dir = Path("hit_frame_detection")
    videos_dir = base_dir / "videos"
    outputs_dir = base_dir / "outputs"
    outputs_old_dir = base_dir / "outputs_old"
    
    try:
        # 2. æ¸…ç†æ—§è¾“å‡ºå¹¶åˆ›å»ºæ–°ç›®å½•
        # if outputs_dir.exists():
        #     if outputs_old_dir.exists():
        #         shutil.rmtree(outputs_old_dir)
        #     shutil.move(outputs_dir, outputs_old_dir)
        
        # if not videos_dir.exists():
        #     videos_dir.mkdir(parents=True)
        
        # outputs_dir.mkdir(exist_ok=True)
        
        # 3. ä¿å­˜ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶
        video_path = videos_dir / "input_video.mp4"
        # ç›´æ¥cpåˆ°video_pathï¼š
        shutil.copy(video_input, video_path)
        
        # 4. æ‰§è¡Œå¤„ç†è„šæœ¬
        src_dir = base_dir / "src"
        subprocess.run(
            ["python", "main.py"],
            cwd=src_dir,
            check=True
        )
        print( "Video processing completed successfully.")
        # 5. å¤„ç†ç»“æœå¹¶è¿”å›
        gallery_items, rally_data, video_info = process_video_result(outputs_dir)
    
        # æ„é€ Dropdownçš„é€‰é¡¹ï¼šæ ¼å¼ä¸º[("æ˜¾ç¤ºæ ‡ç­¾", "å®é™…å€¼"), ...]
        dropdown_choices = [(f"å›åˆ {rid}", path) for rid, path in video_info]
        
        # è¿”å›æ›´æ–°ç»„ä»¶
        rally_choices = gr.Dropdown(choices=dropdown_choices, visible=True)
        return gallery_items, rally_data, rally_choices
        
    except subprocess.CalledProcessError as e:
        print( f"Error during video processing: {e.stderr}")
        error_msg = f"Error processing video: {e.stderr}"
        return error_msg, None
    except Exception as e:
        print( f"Unexpected error: {str(e)}")
        return f"Unexpected error: {str(e)}", None


def process_video_result(outputs_dir):
    """å¤„ç†è¾“å‡ºç›®å½•ä¸­çš„ç»“æœ"""
    # è¯»å–å›åˆJSONæ–‡ä»¶
    rally_json_path = Path(outputs_dir) / "rallies" / "input_video.json"
    with open(rally_json_path, 'r') as f:
        rally_data = json.load(f)
    
    # è·å–è§†é¢‘è¾“å‡ºç›®å½•
    video_output_dir = Path(outputs_dir) / "videos" / "input_video"

    # æ„å»ºGalleryå…¼å®¹æ ¼å¼
    gallery_items = []
    # [(f"å›åˆ {rid}", path) for rid, path in video_info]
    video_info = []
    for rally in rally_data["rally"]:
        start_frame, end_frame, rally_id = rally
        video_path = video_output_dir / f"video_{rally_id}.mp4"
        output_video_path = video_output_dir / f"video_{rally_id}_h264.mp4"
        # ffmpeg -i input.mp4 -c:v libx264 -c:a copy output.mp4
        # è¿™é‡Œä½¿ç”¨ffmpegå°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸ºh264ç¼–ç æ ¼å¼
        # ffmpeg_cmd = f"ffmpeg -y -i {video_path} -c:v libx264 -c:a copy {output_video_path}"
        # subprocess.run(ffmpeg_cmd, shell=True, check=True)
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        # Gradio Galleryæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
        # 1. çº¯æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
        # 2. (æ–‡ä»¶è·¯å¾„, æ ‡é¢˜) çš„å…ƒç»„
        if not video_path.exists():
            print(f"Warning: Video file {video_path} does not exist.")
            continue
        # åŠ è½½è§†é¢‘æ–‡ä»¶:
        # from video_pathï¼š

        print (f"Rally {rally_id}: {video_path}, frames {start_frame}-{end_frame}")
        print(str(video_path))
        video_info.append((rally_id, str(video_path)))
        gallery_items.append((
            str(output_video_path),  # è§†é¢‘æ–‡ä»¶è·¯å¾„
            f"å›åˆ {rally_id}\nå¸§èŒƒå›´: {start_frame}-{end_frame}"  # æ˜¾ç¤ºæ ‡é¢˜
        ))
        
    
    return gallery_items,rally_data,video_info

with gr.Blocks() as demo:
    gr.Markdown("""
        <h1 style='text-align: center;'>åŸºäºè§†è§‰å¤§æ¨¡å‹çš„ä½“è‚²æ™ºèƒ½åˆ†æ</h1>
        <div style='display: flex; justify-content: center; gap: 20px;'>
            <h3 style='text-align: center; color: gray'>2025-srtp jyHu syHu rhXu</h3>
            <a href="https://github.com/opengvlab/VideoChat-Flash-Qwen2_5-2B_res448" target="_blank">
                <img src="https://raw.githubusercontent.com/little612pea/srtp-2025/main/logos/gvlab.jpg" alt="VideoChat-Flash-Qwen2_5-2B_res448" width="50">
            </a>
            <a href="https://github.com/open-mmlab/mmaction2" target="_blank">
                <img src="https://raw.githubusercontent.com/little612pea/srtp-2025/main/logos/mmaction2_logo.png" alt="mmaction2" width="140">
            </a>
            <a href="URL_TO_RAGFLOW" target="_blank">
                <img src="https://raw.githubusercontent.com/little612pea/srtp-2025/main/logos/ragflow-logo.png" alt="ragflow" width="130">
            </a>
            <a href="https://www.bwfbadminton.com/" target="_blank">
                <img src="https://raw.githubusercontent.com/little612pea/srtp-2025/main/logos/BWF-LOGO.jpg" alt="BWF" width="50">
            </a>
            <a href="https://www.itftennis.com/en/" target="_blank">
                <img src="https://raw.githubusercontent.com/little612pea/srtp-2025/main/logos/itf.jpg" alt="ITF" width="121">
            </a>
        </div>
        """)
    with gr.Row():
        with gr.Column(scale=2):
            gr.Markdown("## Collect Info From Video")

            video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
            video_input.GRADIO_CACHE = f"data/{get_today()}"
            segment_button = gr.Button("åˆ†å‰²å›åˆ", variant="primary")
            rally_data = gr.JSON(
                label="åˆ†å‰²ç»“æœ",
                visible=False  # ç¡®ä¿ç»„ä»¶å¯è§
            )
        

            sport_dropdown = gr.Dropdown(
                choices=["ä¹’ä¹“çƒ", "ç¾½æ¯›çƒ", "ç½‘çƒ"],
                label="é€‰æ‹©ä½“è‚²è¿åŠ¨",
                value="ç¾½æ¯›çƒ"
            )
            players_options = ["æ—ä¸¹", "æå®—ä¼Ÿ", "è°Œé¾™", "æ¡ƒç”°è´¤æ–—", "å®‰èµ›é¾™", "çŸ³å®‡å¥‡", "ä¹”çº³å¦Â·å…‹é‡Œæ–¯è’‚", "ææ¢“å˜‰", "å®‰ä¸œå°¼Â·è¥¿å°¼è‹å¡Â·é‡‘å»·", "å‘¨å¤©æˆ"]

            player1_name = gr.Dropdown(
                choices=players_options,
                label="Player 1",
                value="è°Œé¾™"  # Set default selected player
            )

            player2_name = gr.Dropdown(
                choices=players_options,
                label="Player 2",
                value="æ—ä¸¹"  # Set default selected player
            )
            video_dropdown = gr.Dropdown(
                label="é€‰æ‹©å›åˆè§†é¢‘",
                choices=[1,2],  # åˆå§‹ä¸ºç©º
                visible=True,  # åˆå§‹éšè—ï¼Œå¤„ç†å®Œæˆåæ˜¾ç¤º
                value=1
           )
        with gr.Column(scale=6,min_width=700):
            gallery = gr.Gallery(
                label="Generated images", show_label=False, elem_id="gallery"
            , columns=[3], rows=[1], object_fit="contain", height="auto")
            plot_video_action_list = gr.Plot(label="action sequence")
            #ä¸Šä¼ csvæ–‡ä»¶:
            vis_choice =  gr.Dropdown(choices=["player", "ball", "all"], value="player")
            with gr.Column():
                actions_button = gr.Button("Get Action", variant="primary")
                upload_csv_button = gr.Button("Get Match Statistics", variant="primary")
           

            #æ§åˆ¶å¯è§çš„å›¾ä¾‹:


        with gr.Column(scale=4):
            match_segment = gr.Dropdown(
                choices=["ç¬¬ä¸€åœº", "ç¬¬äºŒåœº", "ç¬¬ä¸‰åœº"],
                label="Select Match Segment",
                value="ç¬¬ä¸€åœº"
            )
             
            # æ–°å¢å¯è§†åŒ–æŒ‰é’®
            stats_button = gr.Button("Show Match Stats", variant="primary")
            
            # æ–°å¢ç»Ÿè®¡å›¾è¡¨å±•ç¤ºåŒºåŸŸ
            stats_plot = gr.Plot(label="Match Statistics")
            gr.Markdown("## Match Statistics Visualization")
            plot = gr.Plot(label="Badminton Court",value=draw_badminton_court())
    with gr.Row():
        gr.Markdown("## Build Commentary Agent")    
        with gr.Column():
            gr.Markdown("### è§£è¯´ç”Ÿæˆ")  
            chat_response = gr.Textbox(
                label="AI Commentary",
                placeholder="AI Commentary",
                lines=10
            )
            user_input = gr.Textbox(label="ç”¨æˆ·è¾“å…¥", lines=3)
            qwen_button = gr.Button("æ‰§è¡Œåˆ†æ", variant="primary")
                
        with gr.Column():
            gr.Markdown("### ragflowè§£è¯´å¢å¼º")
            rag_flow_button = gr.Button("Ragflow", variant="primary")
            
        with gr.Column():
            gr.Markdown("### ttsè¯­éŸ³åˆæˆ")
            comment_res = gr.Video(label="video will be shown here")
            voice_choice =  gr.Dropdown(choices=["longlaotie", "longcheng", "longhua"], value="longlaotie")
            voice_button = gr.Button("è¯­éŸ³åˆæˆ", variant="primary")


 # äº¤äº’é€»è¾‘ç»‘å®š

    rag_flow_button.click(
        fn=ragflow_predict,
        inputs=[chat_response, sport_dropdown, player1_name, player2_name],
        outputs=chat_response
    )
    voice_button.click(
        fn=commentary_generator,
        inputs=[video_dropdown,chat_response,rally_data],
        outputs=None
    )
    actions_button.click(
        fn=get_action_plot,
        inputs=[video_dropdown,rally_data],
        outputs=plot_video_action_list
    )
    stats_button.click(
        fn=visualize_match_data,
        inputs=[match_segment],
        outputs=stats_plot
    )
    qwen_button.click(
        fn=qwen_predict,
        inputs=[user_input, sport_dropdown, player1_name, player2_name,rally_data,video_dropdown],
        outputs=chat_response
    )
    upload_csv_button.click(
        fn=draw_match_data,
        inputs=[vis_choice],
        outputs=plot
    )
    segment_button.click(
        fn=segment_video,
        inputs=video_input,
        outputs=[gallery,rally_data,video_dropdown]
    )

if __name__ == "__main__":
    # model, tokenizer, image_processor, max_num_frames, generation_config = get_qwen_model()
    demo.launch(share=True)
